{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english')[::],\"\\n\")  # Should print stopwords list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load dataset (replace with actual file)\n",
    "df = pd.read_csv(r\"CAREGIVERS\\CAREGIVERS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>CGID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2228</td>\n",
       "      <td>16174</td>\n",
       "      <td>RO</td>\n",
       "      <td>Read Only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2229</td>\n",
       "      <td>16175</td>\n",
       "      <td>RO</td>\n",
       "      <td>Read Only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2230</td>\n",
       "      <td>16176</td>\n",
       "      <td>Res</td>\n",
       "      <td>Resident/Fellow/PA/NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231</td>\n",
       "      <td>16177</td>\n",
       "      <td>RO</td>\n",
       "      <td>Read Only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232</td>\n",
       "      <td>16178</td>\n",
       "      <td>RT</td>\n",
       "      <td>Respiratory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID   CGID LABEL            DESCRIPTION\n",
       "0    2228  16174    RO              Read Only\n",
       "1    2229  16175    RO              Read Only\n",
       "2    2230  16176   Res  Resident/Fellow/PA/NP\n",
       "3    2231  16177    RO              Read Only\n",
       "4    2232  16178    RT            Respiratory"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Text Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to \"DESCRIPTION\"\n",
    "df[\"clean_text\"] = df[\"DESCRIPTION\"].astype(str).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels (Convert outcomes to numerical values)\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"encoded_label\"] = label_encoder.fit_transform(df[\"LABEL\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X = df[\"clean_text\"].values  # Features (processed text)\n",
    "y = df[\"encoded_label\"].values  # Target labels (encoded outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization & Padding\n",
    "max_words = 5000  # Max unique words\n",
    "max_len = 200  # Max words per caregiver note\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_pad = pad_sequences(X_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akeer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Output layer for multi-class classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 148ms/step - accuracy: 0.1478 - loss: 4.0704 - val_accuracy: 0.2199 - val_loss: 2.7462\n",
      "Epoch 2/5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 108ms/step - accuracy: 0.2023 - loss: 2.7467 - val_accuracy: 0.2199 - val_loss: 2.7481\n",
      "Epoch 3/5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.2086 - loss: 2.7079 - val_accuracy: 0.2199 - val_loss: 2.7541\n",
      "Epoch 4/5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.2112 - loss: 2.7371 - val_accuracy: 0.2199 - val_loss: 2.7608\n",
      "Epoch 5/5\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - accuracy: 0.2112 - loss: 2.6856 - val_accuracy: 0.2199 - val_loss: 2.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b9f11e4bf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.00      0.00      0.00         1\n",
      "       Admin       0.00      0.00      0.00         8\n",
      "          CM       0.00      0.00      0.00        13\n",
      "       CO-Op       0.00      0.00      0.00         1\n",
      "         CRT       0.00      0.00      0.00         2\n",
      "       Co-Wk       0.00      0.00      0.00         1\n",
      "      Co-Wkr       0.00      0.00      0.00         2\n",
      "      CoOPSt       0.00      0.00      0.00         1\n",
      "        CoOp       0.00      0.00      0.00         1\n",
      "      CoOpSt       0.00      0.00      0.00         3\n",
      "      CoWker       0.00      0.00      0.00        10\n",
      "       CoWkr       0.00      0.00      0.00         4\n",
      "      Coop S       0.00      0.00      0.00         1\n",
      "        Coor       0.00      0.00      0.00         1\n",
      "      CsMngm       0.00      0.00      0.00         1\n",
      "          DI       0.00      0.00      0.00         7\n",
      "          Dr       0.00      0.00      0.00         1\n",
      "         IMD       0.00      0.00      0.00         4\n",
      "      IS Int       0.00      0.00      0.00         1\n",
      "       ISOPS       0.00      0.00      0.00         2\n",
      "      ISSupp       0.00      0.00      0.00         1\n",
      "       LICSW       0.00      0.00      0.00         6\n",
      "          MD       0.00      0.00      0.00       289\n",
      "         MDS       0.00      0.00      0.00         2\n",
      "         MDs       0.00      0.00      0.00        41\n",
      "          MS       0.00      0.00      0.00        20\n",
      "        MSIV       0.00      0.00      0.00         2\n",
      "         MSV       0.00      0.00      0.00         1\n",
      "          Md       0.00      0.00      0.00         1\n",
      "      Med St       0.00      0.00      0.00         1\n",
      "       MedSt       0.00      0.00      0.00         5\n",
      "      MedStu       0.00      0.00      0.00         5\n",
      "      Medica       0.00      0.00      0.00         1\n",
      "          Ms       0.00      0.00      0.00         1\n",
      "         NNP       0.00      0.00      0.00         1\n",
      "          NP       0.00      0.00      0.00         9\n",
      "      NStude       0.00      0.00      0.00         1\n",
      "       OTR/L       0.00      0.00      0.00         1\n",
      "          PA       0.00      0.00      0.00         1\n",
      "          PC       0.00      0.00      0.00         7\n",
      "         PCA       0.00      0.00      0.00         5\n",
      "         PCT       0.00      0.00      0.00        17\n",
      "          PS       0.00      0.00      0.00         1\n",
      "          PT       0.00      0.00      0.00         4\n",
      "      Ph.Stu       0.00      0.00      0.00         2\n",
      "      PhStud       0.00      0.00      0.00         1\n",
      "      PharmD       0.00      0.00      0.00         1\n",
      "       PrADM       0.00      0.00      0.00         1\n",
      "        Prog       0.00      0.00      0.00         1\n",
      "          RA       0.00      0.00      0.00         4\n",
      "          RD       0.00      0.00      0.00        12\n",
      "         RES       0.00      0.00      0.00         2\n",
      "          RF       0.00      0.00      0.00         1\n",
      "          RN       0.00      0.00      0.00       229\n",
      "       RN CM       0.00      0.00      0.00         1\n",
      "         RNC       0.00      0.00      0.00         2\n",
      "        RNCM       0.00      0.00      0.00         1\n",
      "       RNStu       0.00      0.00      0.00         1\n",
      "         RNs       0.00      0.00      0.00         2\n",
      "          RO       0.22      1.00      0.36       333\n",
      "         RPH       0.00      0.00      0.00        16\n",
      "         RPh       0.00      0.00      0.00        11\n",
      "         RRT       0.00      0.00      0.00        30\n",
      "        RRTs       0.00      0.00      0.00         1\n",
      "          RT       0.00      0.00      0.00        20\n",
      "         RTS       0.00      0.00      0.00         2\n",
      "       RTStu       0.00      0.00      0.00         1\n",
      "       Rehab       0.00      0.00      0.00        31\n",
      "         Res       0.00      0.00      0.00       235\n",
      "          SN       0.00      0.00      0.00         4\n",
      "        SNNP       0.00      0.00      0.00         1\n",
      "         SNP       0.00      0.00      0.00         1\n",
      "         SRN       0.00      0.00      0.00         1\n",
      "         SRT       0.00      0.00      0.00         5\n",
      "         STD       0.00      0.00      0.00         4\n",
      "         STN       0.00      0.00      0.00         1\n",
      "          SW       0.00      0.00      0.00        13\n",
      "      SW Int       0.00      0.00      0.00         1\n",
      "       SWInt       0.00      0.00      0.00         1\n",
      "          St       0.00      0.00      0.00         1\n",
      "       StNur       0.00      0.00      0.00         1\n",
      "         Stu       0.00      0.00      0.00         2\n",
      "      StuNur       0.00      0.00      0.00         1\n",
      "       StuRN       0.00      0.00      0.00         1\n",
      "      Studen       0.00      0.00      0.00         3\n",
      "         U A       0.00      0.00      0.00         1\n",
      "          UA       0.00      0.00      0.00         4\n",
      "          UC       0.00      0.00      0.00         2\n",
      "         UCO       0.00      0.00      0.00        19\n",
      "      UCO/PC       0.00      0.00      0.00         1\n",
      "         cda       0.00      0.00      0.00         1\n",
      "         eaw       0.00      0.00      0.00         1\n",
      "          md       0.00      0.00      0.00         1\n",
      "          ms       0.00      0.00      0.00         2\n",
      "         std       0.00      0.00      0.00         1\n",
      "      studen       0.00      0.00      0.00         1\n",
      "         nan       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.22      1514\n",
      "   macro avg       0.00      0.01      0.00      1514\n",
      "weighted avg       0.05      0.22      0.08      1514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Ensure only present labels are used\n",
    "unique_test_labels = np.unique(y_test)\n",
    "target_names = [str(label_encoder.inverse_transform([i])[0]) for i in unique_test_labels]  # Ensure string labels\n",
    "\n",
    "# Generate classification report with zero_division fix\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes, labels=unique_test_labels, target_names=target_names, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>CGID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2228</td>\n",
       "      <td>16174</td>\n",
       "      <td>RO</td>\n",
       "      <td>Read Only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2229</td>\n",
       "      <td>16175</td>\n",
       "      <td>RO</td>\n",
       "      <td>Read Only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2230</td>\n",
       "      <td>16176</td>\n",
       "      <td>Res</td>\n",
       "      <td>Resident/Fellow/PA/NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID   CGID LABEL            DESCRIPTION\n",
       "0    2228  16174    RO              Read Only\n",
       "1    2229  16175    RO              Read Only\n",
       "2    2230  16176   Res  Resident/Fellow/PA/NP"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📌 Step 1: Load Dataset\n",
    "df = pd.read_csv(r\"CAREGIVERS\\CAREGIVERS.csv\")  # Change to your actual file name\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Step 2: Remove labels that appear only once\n",
    "label_counts = df[\"LABEL\"].value_counts()\n",
    "df = df[df[\"LABEL\"].isin(label_counts[label_counts > 1].index)]  # Keep labels with more than 1 occurrence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Step 3: Handle Missing Values in Description\n",
    "df[\"DESCRIPTION\"] = df[\"DESCRIPTION\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Step 4: Text Preprocessing (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(df[\"DESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Step 5: Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"encoded_label\"] = label_encoder.fit_transform(df[\"LABEL\"])\n",
    "y = df[\"encoded_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
